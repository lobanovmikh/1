{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Peer-graded Assignment: Построение baseline-решений\n",
    "Настало время перейти к построению моделей! Давайте начнем с построения так называемых бейзлайнов - построим несколько моделей, которые в дальнейшем будем использовать в качестве первого приближения для будущей модели. Часто для решения подобных задач используются линейные модели, а также ансамбли, например, случайный лес или градиентный бустинг.\n",
    "\n",
    "В этом задании вам предстоит построить несколько моделей и оценить их качество. Эти модели будут служить нам в качестве baseline-решений и пригодятся сразу для нескольких задач:\n",
    "\n",
    "- Во-первых, на разработку baseline-модели не должно уходить много времени (это требование исходит из оценок затрат на проект в целом - большую часть времени все же нужно потратить на основное решение), процесс должен быть простым, на подавляющем большинстве этапов должны использоваться готовые протестированные инструменты. Все это приводит к тому, что baseline-модели - это дешевый способ грубо оценить потенциально возможного качества модели, при построении которого вероятность допущения ошибок относительно невелика.\n",
    "- Во-вторых, использование моделей разного типа при построении baseline'ов позволяет на раннем этапе предположить, какие подходы являются наиболее перспективными и приоритизировать дальнейшие эксперименты.\n",
    "- Наличие baseline-моделей позволяет оценить, какой прирост качества дают различные преобразования, усложнения, оптимизации и прочие активности, которые вы предпринимаете для построения финального решения.\n",
    "- Наконец, если после построения сложного решения оценка его качества будет очень сильно отличаться от оценки качества baseline-моделей, то это будет хорошим поводом поискать в решении ошибки.  \n",
    "\n",
    "Задание будет оцениваться на основе jupyter notebook'а, который вам нужно будет приложить в качестве решения. Убедитесь, что он содержит всю проделанную вами работу, код написан аккуратно и понятно, его легко читать, а также в тексте notebook'а присутствуют необходимые для понимания проделанной вами работы комментарии.\n",
    "\n",
    "## Инструкции\n",
    "Обучите 3 разные baseline-модели на полученных наборах данных и оцените их качество.\n",
    "\n",
    "На прошлой неделе вы выбрали методику оценки качества моделей на основе кросс-валидации, а также основную и вспомогательные метрики. Оцените с их помощью получившуюся модель.\n",
    "\n",
    "Обратите внимание, что под разными моделями понимаются именно разные алгоритмы классификации. Например, 2 модели, реализующие метод k ближайших соседей с разными k, будут считаться одним baseline-решением (хотя и с разными параметрами).\n",
    "\n",
    "Напоминаем, что отложенная выборка (hold-out dataset) не должна использоваться для построения и оценки baseline-моделей!\n",
    "\n",
    "Можно (но не обязательно) рассмотреть следующий набор алгоритмов:\n",
    "\n",
    "- Линейная модель (например, реализация sklearn.linear_model.RidgeClassifier)\n",
    "- Случайный лес (например, реализация sklearn.ensemble.RandomForestClassifier)\n",
    "- Градиентный бустинг (например, реализация sklearn.ensemble.GradientBoostingClassifier)   \n",
    "\n",
    "В качестве решения приложите получившийся jupyter notebook. Убедитесь, что в нем присутствуют:\n",
    "\n",
    "- все baseline-модели, которые вы построили;\n",
    "- качество всех построенных моделей оценено с помощью кросс-валидации, и это понятно из текста в jupyter notebook;\n",
    "- все модели оценены с помощью основной и дополнительных метрик качества."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as ss\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = pd.read_csv('orange_small_churn_data.train.txt')\n",
    "y_data = pd.read_csv('orange_small_churn_labels.train.txt', header=None)\n",
    "y_data.columns = ['Churn']\n",
    "y_data['Churn'] = [0 if x == -1 else x for x in y_data['Churn']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "Na_columns = []\n",
    "\n",
    "for column in x_data.columns: # Колонки, полностью состоящие из NaN\n",
    "    if x_data[column].isna().sum() == x_data.shape[0]:\n",
    "        x_data.drop(column, axis=1,inplace=True)\n",
    "        Na_columns.append(column)\n",
    "        \n",
    "numeric = x_data.loc[:,:'Var190'].columns  \n",
    "categorical = x_data.loc[:,'Var190':].columns        \n",
    "\n",
    "# Колонки с полностью отсутствующими значениями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_hold_out, y, y_hold_out = train_test_split(x_data, \n",
    "                                                    y_data,\n",
    "                                                    test_size=0.1, shuffle=False, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var9</th>\n",
       "      <th>Var10</th>\n",
       "      <th>Var11</th>\n",
       "      <th>...</th>\n",
       "      <th>Var197</th>\n",
       "      <th>Var198</th>\n",
       "      <th>Var199</th>\n",
       "      <th>Var200</th>\n",
       "      <th>Var201</th>\n",
       "      <th>Var202</th>\n",
       "      <th>Var203</th>\n",
       "      <th>Var204</th>\n",
       "      <th>Var205</th>\n",
       "      <th>Var206</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3052.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0LaQ</td>\n",
       "      <td>UaKK0yW</td>\n",
       "      <td>I1sFbv_0IT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EkHG</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>k13i</td>\n",
       "      <td>09_Q</td>\n",
       "      <td>IYzP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1813.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>YFAj</td>\n",
       "      <td>Bnunsla</td>\n",
       "      <td>o64y9zI</td>\n",
       "      <td>DlISMzi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JDd6</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>FbIm</td>\n",
       "      <td>VpdQ</td>\n",
       "      <td>haYg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1953.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>TyGl</td>\n",
       "      <td>fhk21Ss</td>\n",
       "      <td>nQUveAzAF7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dnwD</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>mTeA</td>\n",
       "      <td>VpdQ</td>\n",
       "      <td>hAFG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1533.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0Xwj</td>\n",
       "      <td>uoZk2Zj</td>\n",
       "      <td>LWyxgtXeJL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CwmB</td>\n",
       "      <td>F3hy</td>\n",
       "      <td>vzJD</td>\n",
       "      <td>VpdQ</td>\n",
       "      <td>IYzP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>686.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>vSNn</td>\n",
       "      <td>kugYdIL</td>\n",
       "      <td>ZIXKpoNpqq</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>625Z</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>m_h1</td>\n",
       "      <td>sJzTlal</td>\n",
       "      <td>zm5i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>938.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>JLbT</td>\n",
       "      <td>qMlD1gf</td>\n",
       "      <td>CdPgMY1Z52</td>\n",
       "      <td>IjmTVSM</td>\n",
       "      <td>smXZ</td>\n",
       "      <td>gMVu</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>RVjC</td>\n",
       "      <td>VpdQ</td>\n",
       "      <td>IYzP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1750.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>lK27</td>\n",
       "      <td>Wtcr3WP</td>\n",
       "      <td>qzIoq9b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2qOt</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>m_h1</td>\n",
       "      <td>VpdQ</td>\n",
       "      <td>IYzP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1204.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>487l</td>\n",
       "      <td>FZVtMxl</td>\n",
       "      <td>LH0kFz12FM</td>\n",
       "      <td>hDyVP2J</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bSUY</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>MBhA</td>\n",
       "      <td>09_Q</td>\n",
       "      <td>6JmL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8232.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>487l</td>\n",
       "      <td>gRinF0C</td>\n",
       "      <td>e1XhvTunuD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6wK7</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>7pVf</td>\n",
       "      <td>VpdQ</td>\n",
       "      <td>zm5i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>217.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>kNzO</td>\n",
       "      <td>Xlthli9</td>\n",
       "      <td>J3fgbi2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0xFv</td>\n",
       "      <td>9_Y1</td>\n",
       "      <td>RVjC</td>\n",
       "      <td>VpdQ</td>\n",
       "      <td>zm5i</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 190 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Var1  Var2  Var3  Var4  Var5    Var6  Var7  Var9  Var10  Var11  ...  \\\n",
       "0       NaN   NaN   NaN   NaN   NaN  3052.0   NaN   NaN    NaN    NaN  ...   \n",
       "1       NaN   NaN   NaN   NaN   NaN  1813.0   7.0   NaN    NaN    NaN  ...   \n",
       "2       NaN   NaN   NaN   NaN   NaN  1953.0   7.0   NaN    NaN    NaN  ...   \n",
       "3       NaN   NaN   NaN   NaN   NaN  1533.0   7.0   NaN    NaN    NaN  ...   \n",
       "4       NaN   NaN   NaN   NaN   NaN   686.0   7.0   NaN    NaN    NaN  ...   \n",
       "...     ...   ...   ...   ...   ...     ...   ...   ...    ...    ...  ...   \n",
       "39995   NaN   NaN   NaN   NaN   NaN   938.0   7.0   NaN    NaN    NaN  ...   \n",
       "39996   NaN   NaN   NaN   NaN   NaN  1750.0   7.0   NaN    NaN    NaN  ...   \n",
       "39997   NaN   NaN   NaN   NaN   NaN  1204.0   7.0   NaN    NaN    NaN  ...   \n",
       "39998   NaN   NaN   NaN   NaN   NaN  8232.0  14.0   NaN    NaN    NaN  ...   \n",
       "39999   NaN   NaN   NaN   NaN   NaN   217.0   0.0   NaN    NaN    NaN  ...   \n",
       "\n",
       "       Var197   Var198      Var199   Var200  Var201  Var202  Var203  Var204  \\\n",
       "0        0LaQ  UaKK0yW  I1sFbv_0IT      NaN     NaN    EkHG    9_Y1    k13i   \n",
       "1        YFAj  Bnunsla     o64y9zI  DlISMzi     NaN    JDd6    9_Y1    FbIm   \n",
       "2        TyGl  fhk21Ss  nQUveAzAF7      NaN     NaN    dnwD    9_Y1    mTeA   \n",
       "3        0Xwj  uoZk2Zj  LWyxgtXeJL      NaN     NaN    CwmB    F3hy    vzJD   \n",
       "4        vSNn  kugYdIL  ZIXKpoNpqq      NaN     NaN    625Z    9_Y1    m_h1   \n",
       "...       ...      ...         ...      ...     ...     ...     ...     ...   \n",
       "39995    JLbT  qMlD1gf  CdPgMY1Z52  IjmTVSM    smXZ    gMVu    9_Y1    RVjC   \n",
       "39996    lK27  Wtcr3WP     qzIoq9b      NaN     NaN    2qOt    9_Y1    m_h1   \n",
       "39997    487l  FZVtMxl  LH0kFz12FM  hDyVP2J     NaN    bSUY    9_Y1    MBhA   \n",
       "39998    487l  gRinF0C  e1XhvTunuD      NaN     NaN    6wK7    9_Y1    7pVf   \n",
       "39999    kNzO  Xlthli9     J3fgbi2      NaN     NaN    0xFv    9_Y1    RVjC   \n",
       "\n",
       "        Var205  Var206  \n",
       "0         09_Q    IYzP  \n",
       "1         VpdQ    haYg  \n",
       "2         VpdQ    hAFG  \n",
       "3         VpdQ    IYzP  \n",
       "4      sJzTlal    zm5i  \n",
       "...        ...     ...  \n",
       "39995     VpdQ    IYzP  \n",
       "39996     VpdQ    IYzP  \n",
       "39997     09_Q    6JmL  \n",
       "39998     VpdQ    zm5i  \n",
       "39999     VpdQ    zm5i  \n",
       "\n",
       "[40000 rows x 190 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.iloc[:,:190]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in X[numeric]:\n",
    "    median = X[column].dropna()[X[column].dropna() != 0].median()\n",
    "    X[column].fillna(median, inplace=True)\n",
    "    \n",
    "X[categorical] = X[categorical].fillna('Na_cat') # Замена NaN категор.признаков соотв.категорией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "for column in X[categorical]:\n",
    "    X[column] = le.fit_transform(X[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler # Использование стандартизации\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train[numeric])\n",
    "\n",
    "X_train[numeric] = scaler.transform(X_train[numeric])\n",
    "X_test[numeric] = scaler.transform(X_test[numeric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import (GridSearchCV,\n",
    "                                     train_test_split,\n",
    "                                     StratifiedKFold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Построение моделей\n",
    "\n",
    "# Logistic Regression\n",
    "\n",
    "logreg = LogisticRegression(penalty='l2', random_state=42) #l2 при мультиколлинеарности признаков\n",
    "logreg_model = logreg.fit(X_train, y_train)\n",
    "lr_predictions = logreg.predict(X_test)\n",
    "lr_recall = recall_score(y_test, lr_predictions)\n",
    "lr_f1_score= f1_score(y_test, lr_predictions)\n",
    "lr_roc_auc = roc_auc_score(y_test, lr_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0 0.5\n"
     ]
    }
   ],
   "source": [
    "print(lr_recall, lr_f1_score, lr_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting\n",
    "\n",
    "gbc = GradientBoostingClassifier(random_state=42)\n",
    "gbc_model = gbc.fit(X_train, y_train)\n",
    "gbc_predictions = gbc.predict(X_test)\n",
    "gbc_recall = recall_score(y_test, gbc_predictions)\n",
    "gbc_f1_score = f1_score(y_test, gbc_predictions)\n",
    "gbc_roc_auc = roc_auc_score(y_test, gbc_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.016853932584269662 0.032846715328467155 0.5080519287883843\n"
     ]
    }
   ],
   "source": [
    "print(gbc_recall, gbc_f1_score, gbc_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "rfc_model = random_forest.fit(X_train, y_train)\n",
    "rfc_predictions = random_forest.predict(X_test)\n",
    "random_forest.score(X_train, y_train)\n",
    "rfc_recall = recall_score(y_test, rfc_predictions)\n",
    "rfc_f1_score = f1_score(y_test, rfc_predictions)\n",
    "rfc_roc_auc = roc_auc_score(y_test, rfc_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0 0.5\n"
     ]
    }
   ],
   "source": [
    "print(rfc_recall, rfc_f1_score, rfc_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian = GaussianNB()\n",
    "gauss_model = gaussian.fit(X_train, y_train)\n",
    "gauss_predictions = gaussian.predict(X_test)\n",
    "gauss_recall = recall_score(y_test, gauss_predictions)\n",
    "gauss_f1_score= f1_score(y_test, gauss_predictions)\n",
    "gauss_roc_auc = roc_auc_score(y_test, gauss_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.947565543071161"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gauss_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn_model = knn.fit(X_train, y_train)\n",
    "knn_predictions = knn.predict(X_test)\n",
    "knn_recall = recall_score(y_test, knn_predictions)\n",
    "knn_f1_score= f1_score(y_test, knn_predictions)\n",
    "knn_roc_auc = roc_auc_score(y_test, knn_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00749063670411985"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_recall"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
