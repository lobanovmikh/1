{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Peer-graded Assignment: Построение baseline-решений\n",
    "Настало время перейти к построению моделей! Давайте начнем с построения так называемых бейзлайнов - построим несколько моделей, которые в дальнейшем будем использовать в качестве первого приближения для будущей модели. Часто для решения подобных задач используются линейные модели, а также ансамбли, например, случайный лес или градиентный бустинг.\n",
    "\n",
    "В этом задании вам предстоит построить несколько моделей и оценить их качество. Эти модели будут служить нам в качестве baseline-решений и пригодятся сразу для нескольких задач:\n",
    "\n",
    "- Во-первых, на разработку baseline-модели не должно уходить много времени (это требование исходит из оценок затрат на проект в целом - большую часть времени все же нужно потратить на основное решение), процесс должен быть простым, на подавляющем большинстве этапов должны использоваться готовые протестированные инструменты. Все это приводит к тому, что baseline-модели - это дешевый способ грубо оценить потенциально возможного качества модели, при построении которого вероятность допущения ошибок относительно невелика.\n",
    "- Во-вторых, использование моделей разного типа при построении baseline'ов позволяет на раннем этапе предположить, какие подходы являются наиболее перспективными и приоритизировать дальнейшие эксперименты.\n",
    "- Наличие baseline-моделей позволяет оценить, какой прирост качества дают различные преобразования, усложнения, оптимизации и прочие активности, которые вы предпринимаете для построения финального решения.\n",
    "- Наконец, если после построения сложного решения оценка его качества будет очень сильно отличаться от оценки качества baseline-моделей, то это будет хорошим поводом поискать в решении ошибки.  \n",
    "\n",
    "Задание будет оцениваться на основе jupyter notebook'а, который вам нужно будет приложить в качестве решения. Убедитесь, что он содержит всю проделанную вами работу, код написан аккуратно и понятно, его легко читать, а также в тексте notebook'а присутствуют необходимые для понимания проделанной вами работы комментарии.\n",
    "\n",
    "## Инструкции\n",
    "Обучите 3 разные baseline-модели на полученных наборах данных и оцените их качество.\n",
    "\n",
    "На прошлой неделе вы выбрали методику оценки качества моделей на основе кросс-валидации, а также основную и вспомогательные метрики. Оцените с их помощью получившуюся модель.\n",
    "\n",
    "Обратите внимание, что под разными моделями понимаются именно разные алгоритмы классификации. Например, 2 модели, реализующие метод k ближайших соседей с разными k, будут считаться одним baseline-решением (хотя и с разными параметрами).\n",
    "\n",
    "Напоминаем, что отложенная выборка (hold-out dataset) не должна использоваться для построения и оценки baseline-моделей!\n",
    "\n",
    "Можно (но не обязательно) рассмотреть следующий набор алгоритмов:\n",
    "\n",
    "- Линейная модель (например, реализация sklearn.linear_model.RidgeClassifier)\n",
    "- Случайный лес (например, реализация sklearn.ensemble.RandomForestClassifier)\n",
    "- Градиентный бустинг (например, реализация sklearn.ensemble.GradientBoostingClassifier)   \n",
    "\n",
    "В качестве решения приложите получившийся jupyter notebook. Убедитесь, что в нем присутствуют:\n",
    "\n",
    "- все baseline-модели, которые вы построили;\n",
    "- качество всех построенных моделей оценено с помощью кросс-валидации, и это понятно из текста в jupyter notebook;\n",
    "- все модели оценены с помощью основной и дополнительных метрик качества."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as ss\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = pd.read_csv('orange_small_churn_data.train.txt')\n",
    "y_data = pd.read_csv('orange_small_churn_labels.train.txt', header=None)\n",
    "y_data.columns = ['Churn']\n",
    "y_data['Churn'] = [0 if x == -1 else x for x in y_data['Churn']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "Na_columns = []\n",
    "\n",
    "for column in x_data.columns: # Колонки, полностью состоящие из NaN\n",
    "    if x_data[column].isna().sum() == x_data.shape[0]:\n",
    "        x_data.drop(column, axis=1,inplace=True)\n",
    "        Na_columns.append(column)\n",
    "\n",
    "x_data.loc[:,'Var191':] = x_data.loc[:,'Var191':].fillna('Na_cat') # Замена NaN категор.признаков соотв.категорией\n",
    "\n",
    "# Колонки с полностью отсутствующими значениями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_hold_out, y, y_hold_out = train_test_split(x_data, \n",
    "                                                    y_data,\n",
    "                                                    test_size=0.1, shuffle=False, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in X.loc[:, 'Var1':'Var190']:\n",
    "    median = X[column].dropna()[X[column].dropna() != 0].median()\n",
    "    X[column].fillna(median, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "for column in X.loc[:, 'Var191':]:\n",
    "    X[column] = le.fit_transform(X[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler # Использование стандартизации\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train.loc[:, 'Var1':'Var190'])\n",
    "\n",
    "X_train.loc[:, 'Var1':'Var190'] = scaler.transform(X_train.loc[:, 'Var1':'Var190'])\n",
    "X_test.loc[:, 'Var1':'Var190'] = scaler.transform(X_test.loc[:, 'Var1':'Var190'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import (GridSearchCV,\n",
    "                                     train_test_split,\n",
    "                                     StratifiedKFold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Построение моделей\n",
    "\n",
    "# Logistic Regression\n",
    "\n",
    "logreg = LogisticRegression(penalty='l2', random_state=42) #l2 при мультиколлинеарности признаков\n",
    "logreg_model = logreg.fit(X_train, y_train)\n",
    "lr_predictions = logreg.predict(X_test)\n",
    "lr_recall = recall_score(y_test, lr_predictions)\n",
    "lr_f1_score= f1_score(y_test, lr_predictions)\n",
    "lr_roc_auc = roc_auc_score(y_test, lr_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0 0.5\n"
     ]
    }
   ],
   "source": [
    "print(lr_recall, lr_f1_score, lr_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting\n",
    "\n",
    "gbc = GradientBoostingClassifier(random_state=42)\n",
    "gbc_model = gbc.fit(X_train, y_train)\n",
    "gbc_predictions = gbc.predict(X_test)\n",
    "gbc_recall = recall_score(y_test, gbc_predictions)\n",
    "gbc_f1_score = f1_score(y_test, gbc_predictions)\n",
    "gbc_roc_auc = roc_auc_score(y_test, gbc_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009140767824497258 0.017825311942959002 0.5038939973197339\n"
     ]
    }
   ],
   "source": [
    "print(gbc_recall, gbc_f1_score, gbc_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "rfc_model = random_forest.fit(X_train, y_train)\n",
    "rfc_predictions = random_forest.predict(X_test)\n",
    "random_forest.score(X_train, y_train)\n",
    "rfc_recall = recall_score(y_test, rfc_predictions)\n",
    "rfc_f1_score = f1_score(y_test, rfc_predictions)\n",
    "rfc_roc_auc = roc_auc_score(y_test, rfc_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0 0.5\n"
     ]
    }
   ],
   "source": [
    "print(rfc_recall, rfc_f1_score, rfc_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian = GaussianNB()\n",
    "gauss_model = gaussian.fit(X_train, y_train)\n",
    "gauss_predictions = gaussian.predict(X_test)\n",
    "gauss_recall = recall_score(y_test, gauss_predictions)\n",
    "gauss_f1_score= f1_score(y_test, gauss_predictions)\n",
    "gauss_roc_auc = roc_auc_score(y_test, gauss_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.946983546617916"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gauss_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn_model = knn.fit(X_train, y_train)\n",
    "knn_predictions = knn.predict(X_test)\n",
    "knn_recall = recall_score(y_test, knn_predictions)\n",
    "knn_f1_score= f1_score(y_test, knn_predictions)\n",
    "knn_roc_auc = roc_auc_score(y_test, knn_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003656307129798903"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_recall"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
